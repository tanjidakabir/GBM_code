{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader,WeightedRandomSampler\n",
    "import os \n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from random import choice\n",
    "import numpy as np \n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from monai.networks.blocks import Convolution, ResidualUnit\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_path='./pre_process_data/train/train_index.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=pd.read_csv(data_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_index (arg):\n",
    "    slice_nu=arg['slice_nu']\n",
    "    try_index= [i  for i in range(slice_nu)]\n",
    "    choices_list = []\n",
    "    window_size = arg['window_size']\n",
    "    choose_index=try_index[0+window_size:slice_nu-window_size]\n",
    "    ch = choice(choose_index)\n",
    "    \n",
    "    rn = try_index[ch:ch+window_size]\n",
    "    choices_list.append(rn)\n",
    "    ch_p = ch+1\n",
    "    p_rn = try_index[ch_p:ch_p+window_size]\n",
    "    if np.array(p_rn).max()>slice_nu:\n",
    "        ch_p = ch-1\n",
    "        p_rn = try_index[ch_p:ch_p+window_size]\n",
    "    else:\n",
    "        p_rn = p_rn \n",
    "    choices_list.append(p_rn)\n",
    "    rn_u=list(set(rn).union(set(p_rn)))\n",
    "    try_index_n=list(set(choose_index).difference(set(rn_u)))\n",
    "    ch_n = choice(try_index_n[:-window_size+1])\n",
    "    n_rn = try_index[ch_n:ch_n+window_size]\n",
    "    choices_list.append(n_rn)\n",
    "    return choices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_data (images,slice_index):\n",
    "    query_index=slice_index[0]\n",
    "   \n",
    "    positive_index=slice_index[1]\n",
    "    negative_index=slice_index[2]\n",
    "    query=images[:,:,:,query_index]\n",
    "    positive=images[:,:,:,positive_index]\n",
    "    negative=images[:,:,:,negative_index]\n",
    "    \n",
    "    return query, positive, negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpletrain(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset,arg):\n",
    "        \n",
    "        self.data = dataset\n",
    "        self.arg = arg\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        data_index = self.data.iloc[idx]\n",
    "        images_path=data_index.images_path\n",
    "        with open(images_path, 'rb') as f:\n",
    "            images = pickle.load(f)\n",
    "        input_index=slice_index(self.arg)\n",
    "        \n",
    "        \n",
    "        \n",
    "        query,positive,negative=slice_data (images,input_index)\n",
    "        positive_label=np.array(1.0)\n",
    "        negative_label=np.array(0.0)\n",
    "        \n",
    "        return (query,positive,negative,positive_label,negative_label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Double_conv_encoder_block_in (num_in_filter,args):\n",
    "    input_dim=args['input_dim'] ; kernal_size=args['kernal_size']; pool_kernel_size=args['pool_kernal_size'];\n",
    "    dilation_size=args['dilation_size']; stride_size=args['stride_size'] ; pool_stride_size=args['pool_stride_size'];\n",
    "    padding_size=args['padding_size']; bias=args['bias'] ; act_type= args['act_type'] ; norm_type=args['norm_type'] ; \n",
    "    pool_type=args['pool_type'] ;\n",
    "    \n",
    "    conv1=Convolution(input_dim,num_in_filter,num_in_filter*2, strides=stride_size, \n",
    "                      kernel_size=kernal_size,  dilation=dilation_size,\n",
    "                         bias=bias, conv_only=True,  padding=padding_size)\n",
    "    conv2=Convolution(input_dim,num_in_filter*2,num_in_filter*4, strides=stride_size, \n",
    "                      kernel_size=kernal_size,  dilation=dilation_size,\n",
    "                         bias=bias, conv_only=True,  padding=padding_size)\n",
    "    \n",
    "    if act_type=='PReLU':\n",
    "        act_layer=nn.PReLU()\n",
    "    elif act_type=='SELU':\n",
    "        act_layer=nn.SELU()\n",
    "    elif act_type=='CELU':\n",
    "        act_layer=nn.CELU()\n",
    "    else:\n",
    "        act_layer=nn.ReLU()\n",
    "    \n",
    "    if norm_type=='GroupNorm':\n",
    "        norm_layer_1=nn.GroupNorm(8,num_in_filter*2)\n",
    "        norm_layer_2=nn.GroupNorm(8,num_in_filter*4)\n",
    "    elif act_type=='BatchNorm':\n",
    "        norm_layer_1=nn.LazyBatchNorm3d()\n",
    "        norm_layer_2=nn.LazyBatchNorm3d()\n",
    "    else: \n",
    "        norm_layer_1=nn.LazyInstanceNorm3d()\n",
    "        norm_layer_2=nn.LazyInstanceNorm3d()\n",
    "    \n",
    "    encoder_block=nn.Sequential(OrderedDict(\n",
    "        [('conv1', conv1),\n",
    "        (act_type+'_1', act_layer),\n",
    "        (norm_type+'_1', norm_layer_1),\n",
    "        ('conv2', conv2),\n",
    "        (act_type+'_2', act_layer),\n",
    "        (norm_type+'_2', norm_layer_2)]))\n",
    "    \n",
    "    return encoder_block\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Double_conv_encoder_block_en (num_in_filter,args):\n",
    "    input_dim=args['input_dim'] ; kernal_size=args['kernal_size']; pool_kernel_size=args['pool_kernal_size'];\n",
    "    dilation_size=args['dilation_size']; stride_size=args['stride_size'] ; pool_stride_size=args['pool_stride_size'];\n",
    "    padding_size=args['padding_size']; bias=args['bias'] ; act_type= args['act_type'] ; norm_type=args['norm_type'] ; \n",
    "    pool_type=args['pool_type'] ;\n",
    "    \n",
    "    assert pool_type in ['max', 'avg']\n",
    "    if pool_type == 'avg':\n",
    "        pooling = nn.AvgPool3d(kernel_size=pool_kernel_size, stride=pool_stride_size, padding=0, dilation=1, ceil_mode=False)\n",
    "    else:\n",
    "        pooling = nn.MaxPool3d(kernel_size=pool_kernel_size, stride=pool_stride_size, padding=0, dilation=1, ceil_mode=False)\n",
    "      \n",
    "    \n",
    "    conv1=Convolution(input_dim,num_in_filter*2,num_in_filter*2, strides=stride_size, \n",
    "                      kernel_size=kernal_size,  dilation=dilation_size,\n",
    "                         bias=bias, conv_only=True,  padding=padding_size)\n",
    "    conv2=Convolution(input_dim,num_in_filter*2,num_in_filter*4, strides=stride_size, \n",
    "                      kernel_size=kernal_size,  dilation=dilation_size,\n",
    "                         bias=bias, conv_only=True,  padding=padding_size)\n",
    "    \n",
    "    if act_type=='PReLU':\n",
    "        act_layer=nn.PReLU()\n",
    "    elif act_type=='SELU':\n",
    "        act_layer=nn.SELU()\n",
    "    elif act_type=='CELU':\n",
    "        act_layer=nn.CELU()\n",
    "    else:\n",
    "        act_layer=nn.ReLU()\n",
    "    \n",
    "    if norm_type=='GroupNorm':\n",
    "        norm_layer_1=nn.GroupNorm(8,num_in_filter*2)\n",
    "        norm_layer_2=nn.GroupNorm(8,num_in_filter*4)\n",
    "    elif act_type=='BatchNorm':\n",
    "        norm_layer_1=nn.LazyBatchNorm3d()\n",
    "        norm_layer_2=nn.LazyBatchNorm3d()\n",
    "    else: \n",
    "        norm_layer_1=nn.LazyInstanceNorm3d()\n",
    "        norm_layer_2=nn.LazyInstanceNorm3d()\n",
    "    \n",
    "    encoder_block=nn.Sequential(OrderedDict(\n",
    "        [('pool', pooling),\n",
    "        ('conv1', conv1),\n",
    "        (act_type+'_1', act_layer),\n",
    "        (norm_type+'_1', norm_layer_1),\n",
    "        ('conv2', conv2),\n",
    "        (act_type+'_2', act_layer),\n",
    "        (norm_type+'_2', norm_layer_2)]))\n",
    "    \n",
    "    return encoder_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet_3d_encoder(nn.Module):\n",
    "    def __init__(self, args,en_channel):\n",
    "        super(UNet_3d_encoder, self).__init__()\n",
    "        self.args=args\n",
    "        encoders = []\n",
    "        \n",
    "        input_en=Double_conv_encoder_block_in (en_channel[0],self.args)\n",
    "        encoders.append(input_en)\n",
    "        en_channel.pop(0)\n",
    "        for i in en_channel:\n",
    "            encoder=Double_conv_encoder_block_en (i,self.args)\n",
    "            encoders.append(encoder)\n",
    "        self.encoders=nn.ModuleList(encoders)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # encoder part\n",
    "        encoders_features = []\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x)\n",
    "            # reverse the encoder outputs to be aligned with the decoder\n",
    "            encoders_features.insert(0, x)\n",
    "        final_layer= encoders_features[0]\n",
    "        encoders_features_o = encoders_features[1:]\n",
    "        \n",
    "        return final_layer , encoders_features_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder_mlp(nn.Module):\n",
    "    def __init__(self, encoder, args):\n",
    "        super(encoder_mlp, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.mlp_out_list=args['mlp_out_list']\n",
    "        self.lin_1=nn.LazyLinear(self.mlp_out_list[0])\n",
    "        self.lin_2=nn.LazyLinear(self.mlp_out_list[1])\n",
    "        self.lin_3=nn.LazyLinear(self.mlp_out_list[2])\n",
    "        self.lin_4=nn.LazyLinear(self.mlp_out_list[3])\n",
    "    def forward(self, images ):\n",
    "        out,_=self.encoder(images)\n",
    "        out_size_list=out.size()\n",
    "        reposrnu=out_size_list[1]*out_size_list[2]*out_size_list[3]*out_size_list[4]\n",
    "        out=out.view(-1,reposrnu)\n",
    "        out=self.lin_1(out)\n",
    "        out=self.lin_2(out)\n",
    "        out=self.lin_3(out)\n",
    "        out=self.lin_4(out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder_maps(init_channel_number, number_of_layers):\n",
    "    return [init_channel_number * 2 ** k for k in range(number_of_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "args={}\n",
    "args['slice_nu']=155\n",
    "args['window_size']=10\n",
    "args['batch_size']=20\n",
    "args['mlp_out_list']=[2048,1024,512,256]\n",
    "args['epoch']=300\n",
    "args['input_dim']=3\n",
    "args['kernal_size']=3\n",
    "args['pool_kernal_size']=2\n",
    "args['dilation_size']=1\n",
    "args['stride_size']=1\n",
    "args['pool_stride_size']=2\n",
    "args['padding_size']=1\n",
    "args['bias']=False\n",
    "args['act_type']='PReLU'\n",
    "args['norm_type']='GroupNorm'\n",
    "args['pool_type']='max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['index']=range(len(data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=data_df.sample(frac=0.8)\n",
    "val_df=data_df[~data_df['index'].isin(train_df['index'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=simpletrain(train_df,args)\n",
    "train_loader=DataLoader(train_data,batch_size=args['batch_size'])\n",
    "val_data=simpletrain(val_df,args)\n",
    "val_loader=DataLoader(val_data,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(val_loader))[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 8, 16, 32]\n"
     ]
    }
   ],
   "source": [
    "en_channel=create_encoder_maps(4, 4)\n",
    "en_channel_r=en_channel.copy()\n",
    "en_channel_r.reverse()\n",
    "print(en_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/lazy.py:175: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "model_en=UNet_3d_encoder(args,en_channel)\n",
    "model=encoder_mlp(model_en,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=13\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters(),lr=0.005,weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 120/300 [1:27:32<2:14:00, 44.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_train_loss 461.02841,current_val_loss 366.92928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 150/300 [1:48:24<1:50:08, 44.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_train_loss 321.01111,current_val_loss 267.61401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 156/300 [1:52:33<1:40:46, 41.99s/it]"
     ]
    }
   ],
   "source": [
    "all_train_loss=[]\n",
    "all_val_loss=[]\n",
    "loss_fn=ContrastiveLoss().cuda()\n",
    "loss_fn.requires_grad = True\n",
    "for epoch in tqdm(range(1, args['epoch'] + 1)):\n",
    "    epoch_train_loss=0\n",
    "    for count, batch in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        q_img=batch[0].cuda()\n",
    "        p_img=batch[1].cuda()\n",
    "        n_img=batch[2].cuda()\n",
    "        p_lab=batch[3].cuda()\n",
    "        n_lab=batch[4].cuda()\n",
    "        q_out=model(q_img)\n",
    "        p_out=model(p_img)\n",
    "        n_out=model(n_img)\n",
    "        p_loss=loss_fn(q_out,p_out,p_lab.float())\n",
    "        n_loss=loss_fn(q_out,n_out,n_lab.float())\n",
    "        train_loss=p_loss+n_loss\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        record_loss=train_loss.cpu().data.numpy().item()\n",
    "        epoch_train_loss+=record_loss\n",
    "    epoch_train_loss=epoch_train_loss/count\n",
    "    #print('current_train_loss {:8.5f}'.format(epoch_train_loss))\n",
    "    all_train_loss.append(epoch_train_loss)\n",
    "    if epoch% 30==0:\n",
    "        model.eval()\n",
    "        epoch_val_loss=0\n",
    "        for count, batch in enumerate(val_loader):\n",
    "            q_img=batch[0].cuda()\n",
    "            p_img=batch[1].cuda()\n",
    "            n_img=batch[2].cuda()\n",
    "            p_lab=batch[3].cuda()\n",
    "            n_lab=batch[4].cuda()\n",
    "            with torch.no_grad():\n",
    "                q_out=model(q_img)\n",
    "                p_out=model(p_img)\n",
    "                n_out=model(n_img)\n",
    "                p_loss=loss_fn(q_out,p_out,p_lab)\n",
    "                n_loss=loss_fn(q_out,n_out,n_lab)\n",
    "                val_loss=p_loss+n_loss\n",
    "                record_loss=val_loss.cpu().data.numpy().item()\n",
    "                epoch_val_loss+=record_loss\n",
    "        epoch_val_loss=epoch_val_loss/count\n",
    "        all_val_loss.append(epoch_val_loss)\n",
    "        model_name='3DUNet_encoder_'+str(epoch)+'.pt'\n",
    "        torch.save(model.encoder.state_dict(), './model/3DUNet_encoder_10_pre/'+model_name)\n",
    "        print('current_train_loss {:8.5f},current_val_loss {:8.5f}'.format(epoch_train_loss,epoch_val_loss))\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_en=UNet_3d_encoder(args,en_channel)\n",
    "model_en.load_state_dict(torch.load('./model/3DUNet_encoder_10_pre/3DUNet_encoder_270.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.load_state_dict(torch.load('./model/3DUNet_encoder_10_pre/3DUNet_encoder_270.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "#del model\n",
    "del model_en\n",
    "gc.collect()\n",
    "with torch.cuda.device(device):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_loss_df=pd.DataFrame(all_train_loss,columns=['loss'])\n",
    "all_train_loss_df['epoch']=range(len(all_train_loss_df))\n",
    "all_train_loss_df['epoch']=all_train_loss_df['epoch']+1\n",
    "all_val_loss_df=pd.DataFrame(all_val_loss,columns=['loss'])\n",
    "all_val_loss_df['epoch']=range(len(all_val_loss_df))\n",
    "all_val_loss_df['epoch']=(all_val_loss_df['epoch']+1)*30\n",
    "all_train_loss_df.to_csv('./model/all_loss/train_loss_3DUNet_encoder_pre_slide_10.csv')\n",
    "all_val_loss_df.to_csv('./model/all_loss/val_loss_3DUNet_encoder_pre_slide_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_val_loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('./model/Modified3DUNet_encoder_10_pre/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_en=Modified3DUNet_encoder(in_channels=4)\n",
    "model_en.load_state_dict(torch.load('./model/Modified3DUNet_encoder_10_pre/Modified3DUNet_encoder_300.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_en.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(batch[0].cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_list=batch[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_train_loss/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(q_img,p_img,p_lab.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=ContrastiveLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(images[0]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_out=model_en(images[0]).view(10,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin1=nn.LazyLinear(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin1(encoder_out).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=simpletrain(train_df,arg)\n",
    "train_loader=DataLoader(train_data,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.blocks.convolutions import Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = Convolution(\n",
    "    dimensions=3,\n",
    "    in_channels=4,\n",
    "    out_channels=8,\n",
    "    adn_ordering=\"ADN\",\n",
    "    act=(\"prelu\", {\"init\": 0.2}),\n",
    "    dropout=0.1,\n",
    "    norm=(\"instance\"),\n",
    ")\n",
    "print(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv(images[0]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    ch_n = choice(try_index_n[:-window_size+1])\n",
    "    n_rn = try_index_n[ch_n:ch_n+window_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \n",
    "\n",
    "      def __init__(self, margin=2.0):\n",
    "            super(ContrastiveLoss, self).__init__()\n",
    "            self.margin = margin\n",
    "\n",
    "      def forward(self, output1, output2, label):\n",
    "            # Find the pairwise distance or eucledian distance of two output feature vectors\n",
    "            euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "            # perform contrastive loss calculation with the distance\n",
    "            loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "            (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "            return loss_contrastive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=simpletrain(train_df,arg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.blocks.convolutions import Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = blocks.Convolution(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    adn_ordering=\"ADN\",\n",
    "    act=(\"prelu\", {\"init\": 0.2}),\n",
    "    dropout=0.1,\n",
    "    norm=(\"layer\", {\"normalized_shape\": (10, 10, 10)}),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pt=[]\n",
    "all_modality=[]\n",
    "all_route=[]\n",
    "pt_list=os.listdir(train_data_path)\n",
    "for i in \n",
    "os.listdir(train_data_path+pt_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nib.load(os.path.join(data_folder, data_id) + \"_t1.nii.gz\").get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Optional, Sequence, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from monai.networks.blocks.convolutions import Convolution, ResidualUnit\n",
    "from monai.networks.layers.factories import Act, Norm\n",
    "from monai.networks.layers.simplelayers import SkipConnection\n",
    "from monai.utils import alias, deprecated_arg, export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.nets import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(4, 8, 16),\n",
    "    strides=(2, 1),\n",
    "    num_res_units=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(net.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary(net,torch.zeros((1, 1, 28, 28)), show_input=False, show_hierarchical=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monai.networks.blocks.UpSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = blocks.Convolution(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    adn_ordering=\"ADN\",\n",
    "    act=(\"prelu\", {\"init\": 0.2}),\n",
    "    dropout=0.1,\n",
    "    norm=(\"layer\", {\"normalized_shape\": (10, 10, 10)}),\n",
    ")\n",
    "print(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks.UpSample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
