{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73514b55",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "61eb3a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.util.dtype import dtype_range\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage import exposure\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters import rank\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage import data\n",
    "from skimage import img_as_float\n",
    "from skimage.morphology import reconstruction\n",
    "from scipy import ndimage\n",
    "import random\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import Lambda, RepeatVector, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalMaxPool2D, UpSampling2D\n",
    "from tensorflow.keras.layers import concatenate, add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2b5155",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "41fb787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "dropout=0.2\n",
    "hn = 'he_normal'\n",
    "\n",
    "IMG_HEIGHT=240\n",
    "IMG_WIDTH=240\n",
    "IMG_CHANNELS=4\n",
    "\n",
    "\n",
    "def unet(input_size = (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)):\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv4)\n",
    "    drop4 = Dropout(dropout)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv5)\n",
    "    drop5 = Dropout(dropout)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = hn)(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = hn)(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = hn)(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = hn)(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = hn)(conv9)\n",
    "    #conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    \n",
    "    conv10 = Conv2D(4, (1,1), activation = 'softmax')(conv9)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "    return model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2c303f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet(input_size = (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS))\n",
    "model.compile(optimizer = Adam(lr = 0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "91741a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(patience=8, verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath = 'all_models/model_unet_oct_13_2023.h5',\n",
    "                               verbose=1,\n",
    "                               save_best_only=True, save_weights_only = False)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                              patience=5, min_lr=0.000001, verbose=1,  cooldown=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a3486a",
   "metadata": {},
   "source": [
    "# Load training data and make batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "76af6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.read_csv('df_train.csv')\n",
    "df_test= pd.read_csv('df_test.csv')\n",
    "DATA = 'training_data/'\n",
    "NUMPY_DIR = 'numpy_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "241abccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_batch(row, np_dir=NUMPY_DIR):\n",
    "    \n",
    "    im,lb = get_numpy_img_lbl(row['id'], np_dir)\n",
    "    \n",
    "    n_im = row['rmax']-row['rmin']\n",
    "    rmin=row['rmin']\n",
    "    rmax=row['rmax']\n",
    "    \n",
    "    return normalize_3D_image(im[rmin:rmax]), to_categorical(lb[rmin:rmax],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9f74fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_img_batch(df_batch, np_dir=NUMPY_DIR):\n",
    "    \n",
    "        n_images = (df_batch.rmax - df_batch.rmin).sum()\n",
    "        b_images = np.zeros((n_images, 240, 240, 4), np.float32)\n",
    "        b_label = np.zeros((n_images, 240, 240, 4), np.int8)    \n",
    "        ind=0\n",
    "        for index, row in df_batch.iterrows():\n",
    " \n",
    "            b_im, b_lb = get_img_batch(row, np_dir)\n",
    "            n_im = b_im.shape[0]\n",
    "            b_images[ind:ind+n_im] = b_im\n",
    "            b_label[ind:ind+n_im] = b_lb\n",
    "            ind+=n_im\n",
    "               \n",
    "        return b_images, b_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "27fa9c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_img_lbl(img_id = 'BraTS', np_dir=NUMPY_DIR):\n",
    "    img=np.load(os.path.join(np_dir, img_id+'.npy'))\n",
    "    lbl=np.load(os.path.join(np_dir, img_id+'_lbl.npy'))\n",
    "    return img,lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3db1c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_for_label(lab=2, axis=0, df=df_train,np_dir = NUMPY_DIR):\n",
    "    \n",
    "    img_id= random.choice(df[df['lab'+str(lab)] > 0].id.values)\n",
    "    \n",
    "    img,lbl = get_numpy_img_lbl(img_id, np_dir)\n",
    "    ind = np.where(lbl==lab)\n",
    "    k = random.randrange(len(ind[0]))\n",
    "    \n",
    "    if (axis==0):        \n",
    "        return img[ind[0][k],:,:] , lbl[ind[0][k],:,:]\n",
    "        \n",
    "    lb = np.zeros((240,240),dtype=np.int)\n",
    "    im = np.zeros((240,240,4),dtype=np.float32)\n",
    "    \n",
    "    if (axis==1):\n",
    "        im[40:40+155,:,:]=img[:, ind[1][k],:,:]\n",
    "        lb[40:40+155,:]=lbl[:, ind[1][k],:]\n",
    "        return im,lb\n",
    "    \n",
    "    if (axis == 2):\n",
    "        im[40:40+155,:,:]=img[:, :, ind[2][k],:]\n",
    "        lb[40:40+155,:]=lbl[:,:,ind[2][k]]\n",
    "        return im,lb\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cbc1810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_3D_image(img):\n",
    "    for z in range(img.shape[0]):\n",
    "        for k in range(4):\n",
    "            if (img[z,:,:,k].max()>0):\n",
    "                img[z,:,:,k] /= img[z,:,:,k].max()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7e379ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_2D_image(img):\n",
    "\n",
    "        for c in range(4):\n",
    "            if (img[:,:,c].max()>0):\n",
    "                img[:,:,c] = img[:,:,c]/img[:,:,c].max()\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "06d8eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_faste_train_batch(batch_size = 12, df = df_train ,np_dir=NUMPY_DIR):\n",
    "    \n",
    "    batch_images = np.zeros((batch_size, 240, 240, 4), np.float32)\n",
    "    batch_label = np.zeros((batch_size, 240, 240, 4), np.int8)    \n",
    "    \n",
    "    \n",
    "\n",
    "    while 1:\n",
    "        \n",
    "        df_batch = df.sample(3)\n",
    "        b_images, b_label = get_df_img_batch(df_batch, np_dir)                    \n",
    "        b_images, b_label = shuffle(b_images, b_label)\n",
    "        batch_images[0:batch_size//2]=b_images[0:batch_size//2]\n",
    "        batch_label[0:batch_size//2]=b_label[0:batch_size//2]\n",
    "        \n",
    "        i=batch_size//2\n",
    "        # lab 1\n",
    "        nim = batch_size//4\n",
    "        for j in range(nim):\n",
    "            im,lbl = get_img_for_label(lab=1, axis=random.choice([0,1,2]), df=df)\n",
    "            batch_images[i] = normalize_2D_image(im)\n",
    "            batch_label[i] = to_categorical(lbl, 4)\n",
    "            i+=1\n",
    "                        \n",
    "        # lab 3\n",
    "        nim = batch_size//4\n",
    "        for j in range(nim):\n",
    "            im,lbl = get_img_for_label(lab=3, axis=random.choice([0,1,2]), df=df)\n",
    "            batch_images[i] = normalize_2D_image(im)\n",
    "            batch_label[i] = to_categorical(lbl, 4)\n",
    "            i+=1\n",
    "\n",
    "        batch_images, batch_label = shuffle(batch_images, batch_label)\n",
    "            \n",
    "        yield batch_images, batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0d28b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_im_test_batch(n_images = 3, batch_size=3, df = df_test, np_dir=NUMPY_DIR):\n",
    "\n",
    "    while 1:\n",
    "         \n",
    "        df_batch = df.sample(n_images)\n",
    "        b_images, b_label = get_df_img_batch(df_batch, np_dir)                    \n",
    "        b_images, b_label = shuffle(b_images, b_label)\n",
    "        if (batch_size > 0):\n",
    "            b_images = b_images[0:batch_size]\n",
    "            b_label = b_label[0:batch_size]\n",
    "            \n",
    "        yield b_images, b_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ff44a6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 240, 240, 4), (3, 240, 240, 4))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_train_fast = generate_faste_train_batch(batch_size=3)\n",
    "bimg,blbl = next(gen_train_fast)\n",
    "bimg.shape, blbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e8bdf980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 240, 240, 4), (3, 240, 240, 4))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_test_im = generate_im_test_batch(5)\n",
    "imtest,lbtest = next(gen_test_im)\n",
    "imtest.shape, lbtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b988b5",
   "metadata": {},
   "source": [
    "# Model Training start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d30cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 137s 5s/step - loss: 0.5909 - accuracy: 0.8695 - val_loss: 0.3538 - val_accuracy: 0.9767\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35379, saving model to all_models/model_unet_oct_13_2023.h5\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 55s 2s/step - loss: 0.0981 - accuracy: 0.9788 - val_loss: 0.1374 - val_accuracy: 0.9679\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35379 to 0.13744, saving model to all_models/model_unet_oct_13_2023.h5\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 48s 2s/step - loss: 0.1076 - accuracy: 0.9699 - val_loss: 0.0987 - val_accuracy: 0.9775\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13744 to 0.09871, saving model to all_models/model_unet_oct_13_2023.h5\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 67s 2s/step - loss: 0.0631 - accuracy: 0.9787 - val_loss: 0.0643 - val_accuracy: 0.9807\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09871 to 0.06430, saving model to all_models/model_unet_oct_13_2023.h5\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 90s 3s/step - loss: 0.0701 - accuracy: 0.9782 - val_loss: 0.0626 - val_accuracy: 0.9824\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05274\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 82s 3s/step - loss: 0.0724 - accuracy: 0.9781 - val_loss: 0.0636 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.05274\n",
      "Epoch 8/100\n",
      "19/30 [==================>...........] - ETA: 26s - loss: 0.0907 - accuracy: 0.9724"
     ]
    }
   ],
   "source": [
    "history = model.fit(gen_train_fast,\n",
    "                                        validation_data = gen_test_im, validation_steps=1,\n",
    "                                              steps_per_epoch=30,\n",
    "                              epochs=100,\n",
    "                    callbacks=[earlystopper, checkpointer, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34862f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "324851fd",
   "metadata": {},
   "source": [
    "# Data preprocessing for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38091db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = 'testing_data/'\n",
    "\n",
    "NUMPY_DIR = 'numpy_images_test/'\n",
    "NUMPY_DIR_LABEL = 'numpy_images_test_label/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41ba0394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img_sitk(img):\n",
    "    inputImage = sitk.ReadImage( img )\n",
    "    inputImage = sitk.Cast( inputImage, sitk.sitkFloat32 )\n",
    "    image = sitk.GetArrayFromImage(inputImage)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "daf47100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox2_3D(img):\n",
    "\n",
    "    r = np.any(img, axis=(1, 2))\n",
    "    c = np.any(img, axis=(0, 2))\n",
    "    z = np.any(img, axis=(0, 1))\n",
    "\n",
    "    rmin, rmax = np.where(r)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(c)[0][[0, -1]]\n",
    "    zmin, zmax = np.where(z)[0][[0, -1]]\n",
    "\n",
    "    return [rmin, rmax, cmin, cmax, zmin, zmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "661f8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_into_numpy(dirpath):\n",
    "    \n",
    "    img_id = os.path.basename(dirpath)\n",
    "    np_image=np.zeros((4, 155, 240, 240), dtype=np.float32)\n",
    "    \n",
    "    ## Flair\n",
    "    flair_img = os.path.join(dirpath, img_id+'-t2f.nii.gz')\n",
    "    if (not os.path.isfile(flair_img)):\n",
    "        print(flair_img,' not found aborting')\n",
    "        return None\n",
    "    np_image[0] = read_img_sitk(flair_img)\n",
    "        \n",
    "    ## T1\n",
    "    t1_img = os.path.join(dirpath, img_id+'-t1n.nii.gz')\n",
    "    if (not os.path.isfile(t1_img)):\n",
    "        print(t1_img,' not found aborting')\n",
    "        return None\n",
    "    np_image[1] = read_img_sitk(t1_img)\n",
    "        \n",
    "            \n",
    "    ## T1CE\n",
    "    t1ce_img = os.path.join(dirpath, img_id+'-t1c.nii.gz')\n",
    "    if (not os.path.isfile(t1ce_img)):\n",
    "        print(t1ce_img,' not found aborting')\n",
    "        return None\n",
    "    np_image[2] = read_img_sitk(t1ce_img)\n",
    "    \n",
    "        \n",
    "    ## T2\n",
    "    t2_img = os.path.join(dirpath, img_id+'-t2w.nii.gz')\n",
    "    if (not os.path.isfile(t2_img)):\n",
    "        print(t2_img,' not found aborting')\n",
    "        return None\n",
    "    np_image[3] = read_img_sitk(t2_img)\n",
    "\n",
    "    return np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3be1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lable_into_numpy(dirpath):\n",
    "    \n",
    "    img_id = os.path.basename(dirpath)\n",
    "    np_image=np.zeros((155, 240, 240), dtype=np.int)\n",
    "    \n",
    "    ## lable\n",
    "    lable_img = os.path.join(dirpath, img_id+'-seg.nii.gz')\n",
    "    if (not os.path.isfile(lable_img)):\n",
    "        print(lable_img,' not found aborting')\n",
    "        return None\n",
    "    np_image = read_img_sitk(lable_img).astype(int)\n",
    "\n",
    "    return np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e59810b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "hgg_paths = []\n",
    "for dirpath, dirnames, files in os.walk(DATA):\n",
    "    if ('BraTS' in dirpath):\n",
    "        hgg_paths.append(dirpath)\n",
    "\n",
    "print(len(hgg_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17655727",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type_shrt = ['background', 'necrotic',\n",
    "             'edema', 'enhancing']\n",
    "label_type = ['background', 'necrotic and non-enhancing tumor', 'edema', 'enhancing tumor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7b3fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['id','lab0','lab1','lab2','lab3',\n",
    "                           'rmin','rmax','cmin','cmax','zmin','zmax'])\n",
    "\n",
    "df_val = pd.DataFrame(columns=['id','lab0','lab1','lab2','lab3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89a4c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_df_from_path(df, paths = hgg_paths):\n",
    "    \n",
    "    for f in paths:\n",
    "        np_img = read_image_into_numpy(f)\n",
    "        np_lbl = read_lable_into_numpy(f)\n",
    "        \n",
    "        \n",
    "        new_img = np.zeros((155, 240, 240,4))\n",
    "        for i in range(4):\n",
    "            new_img[:,:,:,i] = np_img[i, :,:,:] \n",
    "            \n",
    "        nimg = os.path.join(NUMPY_DIR,  os.path.basename(f)+'.npy')\n",
    "        np.save(nimg, new_img)\n",
    "        nlbl = os.path.join(NUMPY_DIR_LABEL,  os.path.basename(f)+'_lbl.npy')\n",
    "        np.save(nlbl, np_lbl)\n",
    "\n",
    "        lbls, repeats = np.unique(np_lbl, return_counts=True)\n",
    "        lbl_counts=[0,0,0,0]\n",
    "        for i in range(len(repeats)):\n",
    "            lbl_counts[lbls[i]] = repeats[i]\n",
    "        \n",
    "\n",
    "        vals = [os.path.basename(f)] + lbl_counts + bbox2_3D(np_lbl)\n",
    "        \n",
    "        df.loc[len(df)] = vals\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5bfdfbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_paths = []\n",
    "for dirpath, dirnames, files in os.walk('testing_data/'):\n",
    "    if ('BraTS' in dirpath):\n",
    "        val_paths.append(dirpath)\n",
    "\n",
    "\n",
    "\n",
    "def fill_df_from_path(df=df_val, paths = val_paths):\n",
    "    \n",
    "    for f in paths:\n",
    "        np_img = read_image_into_numpy(f)\n",
    "\n",
    "        new_img = np.zeros((155, 240, 240,4))\n",
    "        for i in range(4):\n",
    "            new_img[:,:,:,i] = np_img[i, :,:,:] \n",
    "\n",
    "        nimg = os.path.join('numpy_images_test',  os.path.basename(f)+'.npy')\n",
    "        np.save(nimg, new_img)\n",
    "        \n",
    "        vals = [os.path.basename(f)]+[0,0,0,0]\n",
    "        df.loc[len(df)] = vals\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bedc741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = fill_df_from_path(df_val, paths = val_paths)\n",
    "\n",
    "df_val.to_csv('df_validation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464643cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_df_from_path(df, paths = hgg_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3918a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "\n",
    "df.to_csv('df_validation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bae9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99f0e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('df_train.csv', index=False)\n",
    "df_test.to_csv('df_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed850805",
   "metadata": {},
   "source": [
    "# Prediction with trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "edede35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrianed_brain_tumor_model=None\n",
    "\n",
    "#pretrianed_brain_tumor_model = keras.models.load_model('./all_models/model_unet_for_brain_tumor.hdf5')\n",
    "pretrianed_brain_tumor_model = load_model('all_models/model_unet_oct_13_2023.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d6a20ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(img, threshold=0.5):\n",
    "    out_img=img.copy()\n",
    "    out_img=np.where(out_img>threshold, 1,0)\n",
    "    return out_img\n",
    "\n",
    "\n",
    "def prediction_from_probabily_3D(img):\n",
    "    \n",
    "    int_image = get_pred(img)\n",
    "    return lbl_from_cat(int_image)\n",
    "\n",
    "\n",
    "def get_prediction_for_batch(pred_batch, threshold=0.5):\n",
    "    \n",
    "    out_batch = np.zeros((pred_batch.shape[0], 240, 240),dtype=np.int)\n",
    "    \n",
    "    for j in range(pred_batch.shape[0]):\n",
    "        pred = get_prediction(pred_batch[j])\n",
    "        if (pred.sum()>0):\n",
    "            print(j, np.unique(pred , return_counts=True))\n",
    "        out_batch[j] = lbl_from_cat(get_prediction(pred_batch[j]))\n",
    "    return out_batch  \n",
    "\n",
    "\n",
    "def get_label_from_pred_batch(labels_batch):\n",
    "    \n",
    "    batch = np.zeros((labels_batch.shape[0], 240, 240), np.uint8)\n",
    "     \n",
    "    for j in range(labels_batch.shape[0]):\n",
    "        batch[j]=get_pred(labels_batch[j,:,:,0])+\\\n",
    "                get_pred(labels_batch[j,:,:,1])*2+\\\n",
    "        get_pred(labels_batch[j,:,:,2])*4\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "def predict_3D_img_prob(np_file):\n",
    "    \n",
    "    np_img = np.load(np_file)\n",
    "    for_pred_img = np.zeros((155, 240, 240, 4), np.float32)\n",
    "\n",
    "    # Normalize image\n",
    "    for_pred_img = normalize_3D_image(np_img)\n",
    "\n",
    "    mdl_pred_img =  pretrianed_brain_tumor_model.predict(for_pred_img)\n",
    "\n",
    "    #pred_label = prediction_from_probabily_3D(mdl_pred_img)\n",
    "\n",
    "    return mdl_pred_img\n",
    "\n",
    "\n",
    "def lbl_from_cat(cat_lbl):\n",
    "    \n",
    "    lbl=0\n",
    "    if (len(cat_lbl.shape)==3):\n",
    "        for i in range(1,4):\n",
    "            lbl = lbl + cat_lbl[:,:,i]*i\n",
    "    elif (len(cat_lbl.shape)==4):\n",
    "        for i in range(1,4):\n",
    "            lbl = lbl + cat_lbl[:,:,:,i]*i\n",
    "    else:\n",
    "        print('Error in lbl_from_cat', cat_lbl.shape)\n",
    "        return None\n",
    "    return lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8887eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_PRED_NUMPY_DIR = 'prediction_numpy/'\n",
    "VALIDATION_PRED_NII_DIR = 'prediction_nii_fcnn/'\n",
    "VALIDATION_NUMPY_DIR = 'numpy_images_test/'\n",
    "\n",
    "\n",
    "for index, row in df_val.iterrows():\n",
    "\n",
    "    img_id = row['id']\n",
    "\n",
    "    nimg = os.path.join(VALIDATION_NUMPY_DIR, img_id+'.npy')\n",
    "    pred_stats = predict_3D_img_prob(nimg)\n",
    "\n",
    "    pred = prediction_from_probabily_3D(pred_stats)\n",
    "\n",
    "    out_img = os.path.join(VALIDATION_PRED_NUMPY_DIR, img_id+'_pred.npy')\n",
    "    np.save(out_img, pred)\n",
    "    \n",
    "    pred = np.where(pred==3,4, pred)\n",
    "    out_nii = os.path.join(VALIDATION_PRED_NII_DIR, img_id+'.nii.gz')\n",
    "\n",
    "    sitk_img = sitk.GetImageFromArray(pred)\n",
    "    sitk.WriteImage(sitk_img , out_nii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd85767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2242c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
